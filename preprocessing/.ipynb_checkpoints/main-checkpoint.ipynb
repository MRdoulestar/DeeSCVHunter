{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "# 使用python-solidity-parser\n",
    "import pprint\n",
    "from solidity_parser import parser\n",
    "import warnings\n",
    "import pickle\n",
    " \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token handle\n",
    "def isphor(s, liter):\n",
    "    m = re.search(liter,s)\n",
    "    if m is not None:\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "def doubisphor(forward, back):\n",
    "    double = ('->','--','-=','+=','++','>=','<=','==','!=','*=','/=','%=','/=','&=','^=','||','&&','>>','<<')\n",
    "    string=forward+back\n",
    "    \n",
    "    if string in double:\n",
    "        return True\n",
    "    else:  \n",
    "        return False\n",
    "    \n",
    "def trisphor(s,t):\n",
    "    if (s=='>>')|(s=='<<')and(t=='='):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "# 分词\n",
    "def tokenize(sentence):\n",
    "    formal='^[_a-zA-Z][_a-zA-Z0-9]*$'\n",
    "    phla='[^_a-zA-Z0-9]'\n",
    "    space='\\s'\n",
    "    spa=''\n",
    "    string=[]\n",
    "    j=0\n",
    "    str = sentence\n",
    "    i=0\n",
    "    \n",
    "    while(i<len(str)):\n",
    "        if isphor(str[i],space):\n",
    "            if i>j:\n",
    "                string.append(str[j:i])\n",
    "                j=i+1\n",
    "            else:\n",
    "                j=i+1\n",
    "                \n",
    "        elif isphor(str[i],phla):    \n",
    "            if (i+1<len(str))and isphor(str[i+1],phla):\n",
    "                m=doubisphor(str[i],str[i+1])\n",
    "                \n",
    "                if m:\n",
    "                    string1=str[i]+str[i+1]\n",
    "                    \n",
    "                    if (i+2<len(str)) and (isphor(str[i+2],phla)):\n",
    "                        if trisphor(string1,str[i+2]):\n",
    "                            string.append(str[j:i])\n",
    "                            string.append(str[i]+str[i+1]+str[i+2])\n",
    "                            j=i+3\n",
    "                            i=i+2\n",
    "                            \n",
    "                        else:\n",
    "                            string.append(str[j:i])\n",
    "                            string.append(str[i]+str[i+1])\n",
    "                            string.append(str[i+2])\n",
    "                            j=i+3\n",
    "                            i=i+2\n",
    "                            \n",
    "                    else:\n",
    "                        string.append(str[j:i])\n",
    "                        string.append(str[i]+str[i+1])\n",
    "                        j=i+2\n",
    "                        i=i+1\n",
    "                        \n",
    "                else:\n",
    "                    string.append(str[j:i])\n",
    "                    string.append(str[i])\n",
    "                    string.append(str[i+1])\n",
    "                    j=i+2\n",
    "                    i=i+1\n",
    "                    \n",
    "            else:\n",
    "                string.append(str[j:i])\n",
    "                string.append(str[i])\n",
    "                j=i+1\n",
    "                \n",
    "        i=i+1\n",
    "        \n",
    "    count=0\n",
    "    count1=0\n",
    "    sub0='\\r'\n",
    "    \n",
    "    if sub0 in string:\n",
    "        string.remove('\\r')\n",
    "        \n",
    "    for sub1 in string:\n",
    "        if sub1==' ':\n",
    "            count1=count1+1\n",
    "            \n",
    "    for j in range(count1):\n",
    "        string.remove(' ')\n",
    "        \n",
    "    for sub in string:\n",
    "        if sub==spa:\n",
    "            count=count+1\n",
    "            \n",
    "    for i in range(count):\n",
    "        string.remove('')\n",
    "        \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split all functions of contracts\n",
    "def my_split_function(filepath):\n",
    "    function_list = []\n",
    "    f = open(filepath, 'r', encoding='utf-8')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    flag = -1\n",
    "\n",
    "    for line in lines:\n",
    "        text = line.strip()\n",
    "        if len(text) > 0 and text != \"\\n\":\n",
    "#             if text.split()[0] == \"function\" or text.split()[0] == \"constructor\":\n",
    "            if text.split()[0] == \"function\":\n",
    "                function_list.append([text])\n",
    "                flag += 1\n",
    "                left_kh = 0\n",
    "                right_kh = 0\n",
    "                if '{' in text:\n",
    "                    left_kh += 1\n",
    "#             elif len(function_list) > 0 and (\"function\" or \"constructor\" in function_list[flag][0]):\n",
    "            elif len(function_list) > 0 and (\"function\" in function_list[flag][0]):\n",
    "                if right_kh == left_kh:\n",
    "                    continue\n",
    "                if '{' in text:\n",
    "                    left_kh += 1\n",
    "                elif '}' in text:\n",
    "                    right_kh += 1\n",
    "                function_list[flag].append(text)\n",
    "                \n",
    "\n",
    "    return function_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 传入sol文件名 解析所有函数\n",
    "# [ {'funcname':funcName, 'funcbody':local_bodys, 'funcparams':funcParams, 'funcvars':funcVars} ]\n",
    "def parseSOL(sol):\n",
    "    result = []\n",
    "    \n",
    "#   用py-ast解析文件中所有contract\n",
    "    sourceUnit = parser.parse_file(sol)\n",
    "    sourceUnitObject = parser.objectify(sourceUnit)\n",
    "    contracts = sourceUnitObject.contracts\n",
    "    \n",
    "#   切分得到所有函数\n",
    "    allFunctionList = my_split_function(sol)\n",
    "#   遍历所有函数\n",
    "    for i in range(len(allFunctionList)):\n",
    "        local_bodys = []\n",
    "        funcParams = []\n",
    "        funcVars = []\n",
    "        funcName = ''\n",
    "        for j in range(len(allFunctionList[i])):\n",
    "            text = allFunctionList[i][j]\n",
    "            local_bodys.append(text)\n",
    "            # get the function name\n",
    "            try:\n",
    "                tmp = re.compile(r'\\b([_A-Za-z]\\w*)\\b(?:(?=\\s*\\w+\\()|(?!\\s*\\w+))')\n",
    "                result_withdraw = tmp.findall(allFunctionList[i][0])\n",
    "                funcName = result_withdraw[1]\n",
    "            except Exception as e:\n",
    "                print('Get funcName error.')\n",
    "                continue\n",
    "        if funcName == '':\n",
    "            continue\n",
    "        #   提取参数和局部变量\n",
    "        for contract in contracts:\n",
    "            functions = contracts[contract].functions.keys()\n",
    "            for function in functions:\n",
    "                if function == funcName:\n",
    "        #           print(contracts[contract].functions[function].arguments.keys())\n",
    "                    declarations = contracts[contract].functions[function].declarations\n",
    "        #           print( declarations.keys() )\n",
    "                    funcParams += [dec for dec in declarations.keys() if declarations[dec]['type'] == 'Parameter']\n",
    "                    funcVars += [dec for dec in declarations.keys() if declarations[dec]['type'] == 'VariableDeclaration']\n",
    "        funcItem = {'funcname':funcName, 'funcbody':local_bodys, 'funcparams':funcParams, 'funcvars':funcVars}\n",
    "        result.append(funcItem)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据关键搜索词找出所有样本函数\n",
    "def getSamples(funcs, search):\n",
    "    samples = []\n",
    "    for k,func in enumerate(funcs):\n",
    "        for line in func['funcbody']:\n",
    "            if search in line:\n",
    "                samples.append(func)\n",
    "                break\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得一个sample的SeSlice的具体实现\n",
    "# {'funcname':funcName, 'funcbody':local_bodys, 'funcparams':funcParams, 'funcvars':funcVars}\n",
    "# {'funcname':funcName, 'funcbody':local_bodys, 'funcparams':funcParams, 'funcvars':funcVars, 'funcSeSlice':funcSeSlice}\n",
    "def getSeSliceImpl(sample, search):\n",
    "    # print(sample['funcparams'], sample['funcvars'])\n",
    "    params = list(filter(None,sample['funcparams']))\n",
    "    vars = list(filter(None,sample['funcvars']))\n",
    "    \n",
    "    # 所有行数\n",
    "    line_num = len(sample['funcbody'])\n",
    "    critical_index = -1\n",
    "    skip_dataflow_flag = False\n",
    "    \n",
    "    # line_inds存储了SeSlice的index\n",
    "    line_inds = []\n",
    "    # 找到切片准则对应行\n",
    "    for k,v in enumerate(sample['funcbody']):\n",
    "        if search in v:\n",
    "            critical_index = k\n",
    "            tks = tokenize(v)\n",
    "            if list( set(tks) & set(vars) ) == [] and list( set(tks) & set(params) ) == []:\n",
    "                skip_dataflow_flag = True\n",
    "            \n",
    "    # 将切片准则行序号 写入SeSlice\n",
    "    line_inds.append(critical_index)\n",
    "    # 默认将函数头部作为一部分\n",
    "    line_inds.append(0)\n",
    "    \n",
    "    # 如果没有找到有变量的切片准则  跳过数据流筛选\n",
    "    if critical_index == -1:\n",
    "        print('No SySlice ...')\n",
    "        return False\n",
    "    \n",
    "    # 数据流筛选  向前找相关行（后向切片）\n",
    "    def DataFlowRecur(lines, index, ses_params=[], ses_vars=[]):\n",
    "        # 获得其中出现的变量/参数\n",
    "#         print(index)\n",
    "#         print(lines[index])\n",
    "        tks = tokenize(lines[index])\n",
    "        for var in vars:\n",
    "            if var in tks:\n",
    "                ses_vars.append(var)\n",
    "        for param in params:\n",
    "            if param in tks:\n",
    "                ses_params.append(param)\n",
    "        ses_params = list(set(ses_params))\n",
    "        ses_vars = list(set(ses_vars))\n",
    "        \n",
    "#         print(ses_vars, ses_params)\n",
    "        # 返回\n",
    "        if len(lines) <= 1:\n",
    "#             print('Out !!!')\n",
    "            return True\n",
    "        \n",
    "        # 每一行看是否存在数据依赖  递归\n",
    "        for k,v in enumerate(lines):\n",
    "            tks = tokenize(v)\n",
    "            if (len( list( set(tks) - set(ses_vars) ) ) > 0) or (len( list( set(tks) - set(ses_params) ) ) > 0):\n",
    "                if k not in line_inds:\n",
    "                    line_inds.append(k)\n",
    "                    DataFlowRecur(lines[:k+1], k, ses_params, ses_vars)\n",
    "\n",
    "    if not skip_dataflow_flag:\n",
    "        # 递归找数据依赖\n",
    "        DataFlowRecur(sample['funcbody'][:critical_index+1], critical_index)\n",
    "\n",
    "    # 去重\n",
    "    line_inds = list( set(line_inds) )\n",
    "#     print(line_inds)\n",
    "    \n",
    "    \n",
    "    # 控制流筛选\n",
    "    def getCtrl(funcbody, inds):\n",
    "        new_inds = []\n",
    "        # 逐个ind判断是否在控制流中\n",
    "        for ind in inds:\n",
    "            # 遍历ind之前的行\n",
    "            if_flag = False\n",
    "            left = 0\n",
    "            right = 0\n",
    "            if_ind = -1\n",
    "            for k, line in enumerate(funcbody[:ind+1]):\n",
    "                if 'if' in line:\n",
    "                    if_flag = True\n",
    "                    if_ind = k\n",
    "                if if_flag:\n",
    "                    if '{' in line:\n",
    "                        left += 1\n",
    "                    if '}' in line:\n",
    "                        right += 1\n",
    "\n",
    "            # 有影响的控制流行\n",
    "            if if_flag and left > right:\n",
    "                new_inds.append(if_ind)\n",
    "                \n",
    "        return new_inds\n",
    "\n",
    "    \n",
    "    # 数据流筛选的句子 判断数据流筛选出来的语句  是否有控制流关系\n",
    "    new_inds = getCtrl(sample['funcbody'], line_inds)\n",
    "    # 加入控制流SeSlice行索引\n",
    "    line_inds += new_inds\n",
    "\n",
    "    # 去重\n",
    "    line_inds = list( set(line_inds) )\n",
    "#     print(line_inds)\n",
    "    \n",
    "    # 排序 获得SeSlice\n",
    "    sample['funcSeSlice'] = []\n",
    "    for k,v in enumerate(sample['funcbody']):\n",
    "        if k in line_inds:\n",
    "            sample['funcSeSlice'].append(v)\n",
    "            \n",
    "    \n",
    "    return sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取SeSlice\n",
    "# 首先判断 SySlice是否在循环/条件语句中\n",
    "# 接着根据数据流/控制流切片\n",
    "# 如果SySlice中没有参数/局部变量 不切片 保留全部函数\n",
    "def getSeSlice(samples, search):\n",
    "    g_samples = []\n",
    "    for k, item in enumerate(samples):\n",
    "        new_item = getSeSliceImpl(item, search)\n",
    "        g_samples.append(new_item)\n",
    "#         print(new_item['funcSeSlice'])\n",
    "    return g_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对变量进行映射\n",
    "# ['filename', 'funcname', 'funcbody', 'funcparams', 'funcvars', 'tokens']\n",
    "# 处理参数和变量中None的情况\n",
    "def mapping(sample):\n",
    "    # funcparams funcvars\n",
    "    params = list(filter(None,sample['funcparams']))\n",
    "    vars = list(filter(None,sample['funcvars']))\n",
    "    # 处理普通funcBody\n",
    "    for ind,line in enumerate(sample['tokens']):\n",
    "        for _,param in enumerate(params):\n",
    "            sample['tokens'][ind] = [ token.replace(param, 'PARAM'+str(_)) if token == param else token  for token in sample['tokens'][ind] ]\n",
    "        for _,var in enumerate(vars):\n",
    "            sample['tokens'][ind] = [ token.replace(var, 'VAR'+str(_)) if token == var else token for token in sample['tokens'][ind] ]\n",
    "    # 处理SeSlice\n",
    "    for ind,line in enumerate(sample['SeSlicetokens']):\n",
    "        for _,param in enumerate(params):\n",
    "            sample['SeSlicetokens'][ind] = [ token.replace(param, 'PARAM'+str(_)) if token == param else token  for token in sample['SeSlicetokens'][ind] ]\n",
    "        for _,var in enumerate(vars):\n",
    "            sample['SeSlicetokens'][ind] = [ token.replace(var, 'VAR'+str(_)) if token == var else token for token in sample['SeSlicetokens'][ind] ]\n",
    "    \n",
    "    return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结合上面的尝试  开始正式处理函数  提取所有漏洞/非漏洞函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14284.sol', '40366.sol', '2189.sol', '27263.sol', '22247.sol']\n",
      "['0', '0', '1', '1', '1']\n",
      "['15.sol', '44.sol', '223.sol', '292.sol', '300.sol']\n",
      "['0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "# 加载label文件\n",
    "with open('./label/reentrancy/reentrancy_contract_label.txt','r') as f:\n",
    "    labels = f.readlines()\n",
    "    reen_labels = [label.strip() for label in labels]\n",
    "with open('./label/reentrancy/reentrancy_contract_name.txt','r') as f:\n",
    "    names = f.readlines()\n",
    "    reen_names = [name.strip() for name in names]\n",
    "    \n",
    "with open('./label/timestamp/timestamp_contract_label.txt','r') as f:\n",
    "    labels = f.readlines()\n",
    "    timestamp_labels = [label.strip() for label in labels]\n",
    "with open('./label/timestamp/timestamp_contract_name.txt','r') as f:\n",
    "    names = f.readlines()\n",
    "    timestamp_names = [name.strip() for name in names]\n",
    "\n",
    "print(reen_names[0:5])\n",
    "print(reen_labels[0:5])\n",
    "          \n",
    "print(timestamp_names[0:5])\n",
    "print(timestamp_labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/timestamp/solidity_contract/5133.sol\n",
      "data/timestamp/solidity_contract/7724.sol\n",
      "data/timestamp/solidity_contract/6348.sol\n",
      "data/timestamp/solidity_contract/11415.sol\n",
      "data/timestamp/solidity_contract/39366.sol\n",
      "data/timestamp/solidity_contract/10253.sol\n",
      "data/timestamp/solidity_contract/11159.sol\n",
      "data/timestamp/solidity_contract/6003.sol\n",
      "data/timestamp/solidity_contract/7519.sol\n",
      "data/timestamp/solidity_contract/6149.sol\n",
      "data/timestamp/solidity_contract/2529.sol\n",
      "data/timestamp/solidity_contract/9483.sol\n",
      "data/timestamp/solidity_contract/6798.sol\n",
      "data/timestamp/solidity_contract/2717.sol\n",
      "data/timestamp/solidity_contract/9695.sol\n",
      "data/timestamp/solidity_contract/9858.sol\n",
      "data/timestamp/solidity_contract/16152.sol\n",
      "data/timestamp/solidity_contract/9333.sol\n",
      "data/timestamp/solidity_contract/11775.sol\n",
      "data/timestamp/solidity_contract/6404.sol\n",
      "data/timestamp/solidity_contract/7736.sol\n",
      "data/timestamp/solidity_contract/11765.sol\n",
      "data/timestamp/solidity_contract/36696.sol\n",
      "data/timestamp/solidity_contract/11407.sol\n",
      "data/timestamp/solidity_contract/7440.sol\n",
      "data/timestamp/solidity_contract/9479.sol\n",
      "data/timestamp/solidity_contract/9445.sol\n",
      "data/timestamp/solidity_contract/1226.sol\n",
      "data/timestamp/solidity_contract/11348.sol\n",
      "data/timestamp/solidity_contract/8766.sol\n",
      "data/timestamp/solidity_contract/16590.sol\n",
      "data/timestamp/solidity_contract/9242.sol\n",
      "data/timestamp/solidity_contract/11566.sol\n",
      "data/timestamp/solidity_contract/8606.sol\n",
      "data/timestamp/solidity_contract/5650.sol\n",
      "data/timestamp/solidity_contract/1813.sol\n",
      "data/timestamp/solidity_contract/4604.sol\n",
      "data/timestamp/solidity_contract/7696.sol\n",
      "data/timestamp/solidity_contract/8598.sol\n",
      "data/timestamp/solidity_contract/9309.sol\n",
      "data/timestamp/solidity_contract/7330.sol\n",
      "data/timestamp/solidity_contract/1027.sol\n",
      "data/timestamp/solidity_contract/6833.sol\n",
      "data/timestamp/solidity_contract/12044.sol\n",
      "data/timestamp/solidity_contract/11773.sol\n",
      "data/timestamp/solidity_contract/7753.sol\n",
      "data/timestamp/solidity_contract/10146.sol\n",
      "data/timestamp/solidity_contract/10807.sol\n",
      "data/timestamp/solidity_contract/7419.sol\n",
      "data/timestamp/solidity_contract/1518.sol\n",
      "data/timestamp/solidity_contract/1041.sol\n",
      "data/timestamp/solidity_contract/11339.sol\n",
      "data/timestamp/solidity_contract/10755.sol\n",
      "data/timestamp/solidity_contract/7593.sol\n",
      "data/timestamp/solidity_contract/5353.sol\n",
      "data/timestamp/solidity_contract/8139.sol\n",
      "data/timestamp/solidity_contract/28157.sol\n",
      "data/timestamp/solidity_contract/8305.sol\n",
      "data/timestamp/solidity_contract/33575.sol\n",
      "Get funcName error.\n",
      "data/timestamp/solidity_contract/13458.sol\n",
      "data/timestamp/solidity_contract/10186.sol\n",
      "data/timestamp/solidity_contract/5580.sol\n",
      "data/timestamp/solidity_contract/10233.sol\n",
      "data/timestamp/solidity_contract/8099.sol\n",
      "data/timestamp/solidity_contract/2563.sol\n",
      "data/timestamp/solidity_contract/9998.sol\n",
      "data/timestamp/solidity_contract/1456.sol\n",
      "data/timestamp/solidity_contract/9750.sol\n",
      "data/timestamp/solidity_contract/667.sol\n",
      "data/timestamp/solidity_contract/35897.sol\n",
      "data/timestamp/solidity_contract/9208.sol\n",
      "data/timestamp/solidity_contract/1697.sol\n",
      "data/timestamp/solidity_contract/5591.sol\n",
      "data/timestamp/solidity_contract/11128.sol\n",
      "data/timestamp/solidity_contract/35713.sol\n",
      "data/timestamp/solidity_contract/9802.sol\n",
      "data/timestamp/solidity_contract/1735.sol\n",
      "data/timestamp/solidity_contract/470.sol\n",
      "data/timestamp/solidity_contract/11539.sol\n",
      "data/timestamp/solidity_contract/10431.sol\n",
      "data/timestamp/solidity_contract/15.sol\n",
      "data/timestamp/solidity_contract/9779.sol\n",
      "data/timestamp/solidity_contract/10369.sol\n",
      "Get funcName error.\n",
      "Get funcName error.\n",
      "Get funcName error.\n",
      "data/timestamp/solidity_contract/11711.sol\n",
      "data/timestamp/solidity_contract/2821.sol\n",
      "data/timestamp/solidity_contract/466.sol\n",
      "data/timestamp/solidity_contract/300.sol\n",
      "data/timestamp/solidity_contract/6272.sol\n",
      "data/timestamp/solidity_contract/10547.sol\n",
      "data/timestamp/solidity_contract/739.sol\n",
      "data/timestamp/solidity_contract/20888.sol\n",
      "data/timestamp/solidity_contract/4699.sol\n",
      "data/timestamp/solidity_contract/10022.sol\n",
      "data/timestamp/solidity_contract/10803.sol\n",
      "data/timestamp/solidity_contract/39091.sol\n",
      "data/timestamp/solidity_contract/9987.sol\n",
      "data/timestamp/solidity_contract/9978.sol\n",
      "data/timestamp/solidity_contract/20259.sol\n",
      "data/timestamp/solidity_contract/7570.sol\n",
      "Get funcName error.\n",
      "data/timestamp/solidity_contract/10826.sol\n",
      "data/timestamp/solidity_contract/11457.sol\n",
      "data/timestamp/solidity_contract/6929.sol\n",
      "data/timestamp/solidity_contract/1288.sol\n",
      "data/timestamp/solidity_contract/38239.sol\n",
      "data/timestamp/solidity_contract/11640.sol\n",
      "data/timestamp/solidity_contract/8939.sol\n",
      "data/timestamp/solidity_contract/9428.sol\n",
      "data/timestamp/solidity_contract/292.sol\n",
      "data/timestamp/solidity_contract/5400.sol\n",
      "data/timestamp/solidity_contract/8497.sol\n",
      "data/timestamp/solidity_contract/9210.sol\n",
      "data/timestamp/solidity_contract/10831.sol\n",
      "data/timestamp/solidity_contract/11642.sol\n",
      "data/timestamp/solidity_contract/4481.sol\n",
      "data/timestamp/solidity_contract/8293.sol\n",
      "data/timestamp/solidity_contract/6297.sol\n",
      "data/timestamp/solidity_contract/10763.sol\n",
      "data/timestamp/solidity_contract/10159.sol\n",
      "data/timestamp/solidity_contract/7214.sol\n",
      "data/timestamp/solidity_contract/4523.sol\n",
      "data/timestamp/solidity_contract/9759.sol\n",
      "data/timestamp/solidity_contract/11727.sol\n",
      "data/timestamp/solidity_contract/11257.sol\n",
      "data/timestamp/solidity_contract/11243.sol\n",
      "data/timestamp/solidity_contract/11323.sol\n",
      "data/timestamp/solidity_contract/4645.sol\n",
      "data/timestamp/solidity_contract/17949.sol\n",
      "data/timestamp/solidity_contract/10559.sol\n",
      "data/timestamp/solidity_contract/4453.sol\n",
      "data/timestamp/solidity_contract/11684.sol\n",
      "data/timestamp/solidity_contract/22273.sol\n",
      "data/timestamp/solidity_contract/11861.sol\n",
      "data/timestamp/solidity_contract/5572.sol\n",
      "data/timestamp/solidity_contract/7775.sol\n",
      "data/timestamp/solidity_contract/11526.sol\n",
      "data/timestamp/solidity_contract/10758.sol\n",
      "data/timestamp/solidity_contract/15422.sol\n",
      "Get funcName error.\n",
      "Get funcName error.\n",
      "data/timestamp/solidity_contract/33354.sol\n",
      "data/timestamp/solidity_contract/9820.sol\n",
      "data/timestamp/solidity_contract/22714.sol\n",
      "data/timestamp/solidity_contract/8647.sol\n",
      "data/timestamp/solidity_contract/6454.sol\n",
      "data/timestamp/solidity_contract/44.sol\n",
      "data/timestamp/solidity_contract/12075.sol\n",
      "data/timestamp/solidity_contract/11568.sol\n",
      "data/timestamp/solidity_contract/9502.sol\n",
      "data/timestamp/solidity_contract/12115.sol\n",
      "data/timestamp/solidity_contract/11346.sol\n",
      "data/timestamp/solidity_contract/11178.sol\n",
      "data/timestamp/solidity_contract/6220.sol\n",
      "data/timestamp/solidity_contract/22438.sol\n",
      "Get funcName error.\n",
      "data/timestamp/solidity_contract/18771.sol\n",
      "data/timestamp/solidity_contract/9918.sol\n",
      "data/timestamp/solidity_contract/10661.sol\n",
      "data/timestamp/solidity_contract/2252.sol\n",
      "data/timestamp/solidity_contract/11351.sol\n",
      "data/timestamp/solidity_contract/17907.sol\n",
      "data/timestamp/solidity_contract/8233.sol\n",
      "data/timestamp/solidity_contract/8555.sol\n",
      "data/timestamp/solidity_contract/11191.sol\n",
      "data/timestamp/solidity_contract/1570.sol\n",
      "data/timestamp/solidity_contract/9892.sol\n",
      "data/timestamp/solidity_contract/10933.sol\n",
      "data/timestamp/solidity_contract/6753.sol\n",
      "data/timestamp/solidity_contract/7511.sol\n",
      "data/timestamp/solidity_contract/6743.sol\n",
      "data/timestamp/solidity_contract/14953.sol\n",
      "data/timestamp/solidity_contract/6596.sol\n",
      "data/timestamp/solidity_contract/1824.sol\n",
      "data/timestamp/solidity_contract/30012.sol\n",
      "data/timestamp/solidity_contract/16957.sol\n",
      "data/timestamp/solidity_contract/10129.sol\n",
      "data/timestamp/solidity_contract/37390.sol\n",
      "data/timestamp/solidity_contract/4619.sol\n",
      "data/timestamp/solidity_contract/593.sol\n",
      "data/timestamp/solidity_contract/9329.sol\n",
      "data/timestamp/solidity_contract/7338.sol\n",
      "data/timestamp/solidity_contract/11182.sol\n",
      "data/timestamp/solidity_contract/9843.sol\n",
      "data/timestamp/solidity_contract/7891.sol\n",
      "data/timestamp/solidity_contract/223.sol\n",
      "data/timestamp/solidity_contract/11418.sol\n",
      "data/timestamp/solidity_contract/10855.sol\n",
      "Get funcName error.\n",
      "data/timestamp/solidity_contract/6806.sol\n",
      "data/timestamp/solidity_contract/11949.sol\n",
      "308\n"
     ]
    }
   ],
   "source": [
    "# 正式开始提取数据集函数\n",
    "# 标准化 VAR0 PARAM0 映射\n",
    "# 根据数据流、控制流提取SeSlice\n",
    "\n",
    "# call.value\n",
    "# block.timestamp\n",
    "vultype = 'timestamp'\n",
    "# vultype = 'reentrancy'\n",
    "\n",
    "\n",
    "data = {'good':[], 'bad':[]}\n",
    "sumfunc = 0\n",
    "\n",
    "basepath = 'data/' + vultype + '/solidity_contract/'\n",
    "sols = os.listdir(basepath)\n",
    "\n",
    "for sol in sols:\n",
    "#     if not sol == '21697.sol':\n",
    "#         continue\n",
    "    # 文件路径\n",
    "    solpath = basepath + sol\n",
    "    print(solpath)\n",
    "    if vultype == 'reentrancy':\n",
    "        index = reen_names.index(sol)\n",
    "        label = reen_labels[index]\n",
    "        search = 'call.value'\n",
    "    elif vultype == 'timestamp':\n",
    "        index = timestamp_names.index(sol)\n",
    "        label = timestamp_labels[index]\n",
    "        search = 'block.timestamp'\n",
    "        \n",
    "    # 解析所有函数\n",
    "    try:\n",
    "        funcs = parseSOL(solpath)\n",
    "    except Exception as e:\n",
    "        print('Parse sol error.')\n",
    "        continue\n",
    "    # 寻找数据集样本函数\n",
    "    # {'funcname':funcName, 'funcbody':local_bodys, 'funcparams':funcParams, 'funcvars':funcVars}\n",
    "    samples = getSamples(funcs, search)\n",
    "    # {'funcname':funcName, 'funcbody':local_bodys, 'funcparams':funcParams, 'funcvars':funcVars, 'funcSeSlice'}\n",
    "    # print(samples)\n",
    "    \n",
    "    # SeSlice提取\n",
    "    samples = getSeSlice(samples, search)\n",
    "    \n",
    "#     print(samples[0]['funcSeSlice'])\n",
    "#     break\n",
    "    \n",
    "    # 统计函数数量\n",
    "    sumfunc += len(samples)\n",
    "    # 每一行  分词\n",
    "    for k,sample in enumerate(samples):\n",
    "        functokens = []\n",
    "        seslicetokens = []\n",
    "        for line in sample['funcbody']:\n",
    "            functokens.append(tokenize(line))\n",
    "        for line in sample['funcSeSlice']:\n",
    "            seslicetokens.append(tokenize(line))\n",
    "        samples[k]['tokens'] = functokens\n",
    "        samples[k]['SeSlicetokens'] = seslicetokens\n",
    "        samples[k]['filename'] = solpath\n",
    "        # 对行的token进行标准化 避免标准化出现错误  如st->VAR0 state->VAR0ate\n",
    "        samples[k] = mapping(samples[k])\n",
    "#         if k == 2:\n",
    "#             print(samples[k]['SeSlicetokens'])\n",
    "        # ['filename', 'funcname', 'funcbody', 'funcparams', 'funcvars', 'funcSeSlice', 'tokens', 'SeSlicetokens']\n",
    "        if label == '0':\n",
    "            data['good'].append(samples[k])\n",
    "        else:\n",
    "            data['bad'].append(samples[k])\n",
    "#     except Exception as e:\n",
    "#         print('error',e)\n",
    "#     break\n",
    "\n",
    "    \n",
    "#     break\n",
    "\n",
    "# 重入漏洞 211个函数\n",
    "# 时间戳漏洞 308个函数\n",
    "print(sumfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存文件\n",
    "# with open('train_data/data_'+vultype+'.pkl','wb') as f:\n",
    "with open('train_data/dfcf_data_'+vultype+'.pkl','wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "981"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max = 0\n",
    "min = 999\n",
    "for item in data['good']:\n",
    "    temp = []\n",
    "    for tokens in item['tokens']:\n",
    "        temp += [token for token in tokens]\n",
    "    length = len(temp)\n",
    "    if length > max:\n",
    "        max = length\n",
    "    if length < min:\n",
    "        min = length\n",
    "max\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分成训练集/测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Blockchain/tools/GNNSCVulDetector_new/train_data/reentrancy/train.json', 'r') as f:\n",
    "    train_json = eval(f.read())\n",
    "with open('Blockchain/tools/GNNSCVulDetector_new/train_data/reentrancy/valid.json', 'r') as f:\n",
    "    valid_json = eval(f.read()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sols = [item['contract_name'] for item in train_json]\n",
    "valid_sols = [item['contract_name'] for item in valid_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
